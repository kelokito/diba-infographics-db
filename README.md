# ğŸ“˜ **README**

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ db_connection.py
â”‚   â””â”€â”€ queries/
â”‚        â”œâ”€â”€ bibliographics_queries.sql
â”‚        â”œâ”€â”€ users_queries.sql
â”‚        â””â”€â”€ general_queries.sql
â”‚
â”œâ”€â”€ bibliographics/
â”‚   â”œâ”€â”€ bibliographics_data.py
â”‚   â””â”€â”€ bibliographics_repository.py
â”‚
â”œâ”€â”€ users/
â”‚   â”œâ”€â”€ users_data.py
â”‚   â””â”€â”€ users_repository.py
â”‚
â”œâ”€â”€ general/
â”‚   â”œâ”€â”€ general_data.py
â”‚   â””â”€â”€ general_repository.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ dashboard_service.py
â”‚   â””â”€â”€ dashboard_view.py
â”‚
â””â”€â”€ models/
    â”œâ”€â”€ bibliographics_model.py
    â”œâ”€â”€ users_model.py
    â””â”€â”€ general_model.py
```

---

# ğŸš€ **1. Requirements**

You need:

* Python 3.9+
* Docker & Docker Compose
* `pip`
* Optionally pgAdmin (already included in docker-compose.yml)

---

# ğŸ³ **2. Running PostgreSQL with Docker**

Start the database and pgAdmin:

```bash
docker-compose up -d
```

To stop:

```bash
docker-compose down
```

### Database connection info (default)

| Item     | Value        |
| -------- | ------------ |
| Host     | localhost    |
| Port     | 5432         |
| User     | postgres     |
| Password | password     |
| DB name  | dashboard_db |

pgAdmin:
ğŸ“ [http://localhost:8080](http://localhost:8080)
Login: [admin@admin.com](mailto:admin@admin.com) / admin

---

# ğŸ›  **3. Python Setup**

### Step 1 â€” Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate     # macOS/Linux
venv\Scripts\activate        # Windows
```

### Step 2 â€” Install Requirements

```bash
pip install -r requirements.txt
```

---

# ğŸ”§ **4. Configure Environment Variables**

Create a `.env` file:

```
DB_HOST=localhost
DB_NAME=dashboard_db
DB_USER=postgres
DB_PASSWORD=password
```

---

# ğŸ—„ **5. Create Tables**

Run SQL schema files manually:

```bash
psql -h localhost -U postgres -d dashboard_db -f src/db/queries/bibliographics_queries.sql
psql -h localhost -U postgres -d dashboard_db -f src/db/queries/users_queries.sql
psql -h localhost -U postgres -d dashboard_db -f src/db/queries/general_queries.sql
```

---

# ğŸ“¥ **6. Ingest All Data**

Place your manually downloaded data files in:

```
/data/bibliographics.csv
/data/users.csv
/data/general.csv
```

Run ingestion:

```bash
python ingest_all.py
```

This:

* Loads .env
* Parses CSVs
* Inserts into all 3 tables

---

# ğŸ“Š **7. Run the Dashboard**

Depends on your view implementation.
If using Streamlit:

```bash
streamlit run src/dashboard/dashboard_view.py
```

If using a CLI view:

```bash
python -m src.dashboard.dashboard_view
```

---

# ğŸ§ª **8. Testing**

```bash
pytest
```

---

# ğŸ“¦ **9. Quick Commands**

| Action            | Command                                         |
| ----------------- | ----------------------------------------------- |
| Start DB          | `docker-compose up -d`                          |
| Stop DB           | `docker-compose down`                           |
| Ingest everything | `python ingest_all.py`                          |
| Run dashboard     | `streamlit run src/dashboard/dashboard_view.py` |
